{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0b5806dc0e8395af2278a83b10faec683de35099ebc749f75874e48097d605efb",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import data_handler\n",
    "import machine_learning as ml\n",
    "import cost_benefit as cb\n",
    "\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import graphviz \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "## Main results for seminar paper\n",
    "This notebook is created to estimate the machine learning models for the chosen hyperparameters. See other notebook for invokement of the grid search algorithm to choose the optimal hyperparameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define wrapper to call all necessary functions.\n",
    "def result_wrapper(model, parameters, train, test, name, scoring='recall'):\n",
    "    # I have to create a fake class in order to make validate model work.\n",
    "    # This is because it was created with the purpose to work with the\n",
    "    # grid search algorithm.\n",
    "    x, y = train[0], train[1]\n",
    "\n",
    "    class Object(object):\n",
    "        pass\n",
    "    model_obj = Object()\n",
    "    model_obj.best_estimator_ = model(**parameters).fit(x, y)\n",
    "    best_model = ml.validate_model(model_obj, train, test, scoring=scoring, supress_print=True)\n",
    "    benefits = cb.cost_benefit_analysis(best_model, test)\n",
    "    print(f\"{name} & {benefits[3]} & {benefits[0]:.2f} & {benefits[1]/benefits[0]*100:.2f} & {benefits[2]/benefits[0]*100:.2f} \\\\\\\\\")\n",
    "    print()\n",
    "    print('\\\\begin{table}[!hb]')\n",
    "    print('\\\\centering')\n",
    "    print(f'\\\\caption{{Confusion matrix for {name} model}} ')\n",
    "    print('\\\\begin{minipage}{.5\\\\linewidth}')\n",
    "    print('\\\\caption*{Train results}')\n",
    "    cb.latex_printout(best_model, train)\n",
    "    print('\\\\end{minipage}')\n",
    "    print('\\\\begin{minipage}{.5\\\\linewidth}')\n",
    "    print('\\\\caption*{Test results}')\n",
    "    cb.latex_printout(best_model, test)\n",
    "    print('\\\\end{minipage}')\n",
    "    print('\\\\end{table}')\n",
    "    return best_model"
   ]
  },
  {
   "source": [
    "### Ohlson's Logit\n",
    "I first define a function to run Ohlson's logit function, with the specified variables. I then evaluate it both in it's success at predicting bankruptcies, but also how much savings we expect."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohlson_data(year):\n",
    "    x_train, x_test, y_train, y_test = data_handler.load_data(year)\n",
    "    n = y_train.size\n",
    "    x_train.columns = data_handler.ohlson_varnames()\n",
    "    x_test.columns = data_handler.ohlson_varnames()\n",
    "\n",
    "    # Ohlson use a dummy if liabilites are greater than assets\n",
    "    x_train['liabilites > assets'] = (x_train['total liabilities / total assets'] > 1)*1.0\n",
    "    x_test['liabilites > assets'] = (x_test['total liabilities / total assets'] > 1)*1.0\n",
    "\n",
    "    # Try to replicate the variables as closely as possible,\n",
    "    # some of the variables are inverted, but that should not affect\n",
    "    # the predictability, only the sign of the coefficient.\n",
    "    ohlson_vars = [\n",
    "        'logarithm of total assets', \n",
    "        'total liabilities / total assets', \n",
    "        'working capital / total assets', \n",
    "        'current assets / short-term liabilities',\n",
    "        'liabilites > assets',\n",
    "        'net profit / total assets',\n",
    "        'total liabilities / ((profit on operating activities + depreciation) * (12/365))',\n",
    "        'sales (n) / sales (n-1)'\n",
    "    ]\n",
    "    x_ohlson_train = x_train[ohlson_vars]\n",
    "    x_ohlson_test = x_test[ohlson_vars]\n",
    "    return x_ohlson_train, x_ohlson_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ohlson's logit & 3 & 68.71 & 0.10 & 0.17 \\\\\n\n\\begin{table}[!hb]\n\\centering\n\\caption{Confusion matrix for Ohlson's logit} model\n\\begin{minipage}{.5\\linewidth}\n\\caption*{Train results}\n\\begin{tabular}{lrr}\n\\hline\n              &   Non-Bankrupt &   Bankrupt \\\\\n\\hline\n Non-Bankrupt &           4379 &         21 \\\\\n Bankrupt     &            306 &         22 \\\\\n\\hline\n\\end{tabular}\n\\end{minipage}\n\\begin{minipage}{.5\\linewidth}\n\\caption*{Test results}\n\\begin{tabular}{lrr}\n\\hline\n              &   Non-Bankrupt &   Bankrupt \\\\\n\\hline\n Non-Bankrupt &           1095 &          5 \\\\\n Bankrupt     &             79 &          3 \\\\\n\\hline\n\\end{tabular}\n\\end{minipage}\n\\end{table}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = ohlson_data(5)\n",
    "ohlson_parameters = {'penalty': 'none', 'max_iter': 1000}\n",
    "result_wrapper(LogisticRegression, ohlson_parameters, (x_train, y_train), (x_test, y_test), \"Ohlson's logit\") ;"
   ]
  },
  {
   "source": [
    "### Logit with elastic net\n",
    "This is an extension of Ohlson's logit model. This time we include all available variables. Since this can lead to overfitting, we use elastic-net to reduce this problem."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/karl/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "Logit & 9 & 68.71 & 0.46 & 0.77 \\\\\n",
      "\n",
      "\\begin{table}[!hb]\n",
      "\\centering\n",
      "\\caption{Confusion matrix for Logit model} \n",
      "\\begin{minipage}{.5\\linewidth}\n",
      "\\caption*{Train results}\n",
      "\\begin{tabular}{lrr}\n",
      "\\hline\n",
      "              &   Non-Bankrupt &   Bankrupt \\\\\n",
      "\\hline\n",
      " Non-Bankrupt &           4378 &         22 \\\\\n",
      " Bankrupt     &            301 &         27 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{minipage}\n",
      "\\begin{minipage}{.5\\linewidth}\n",
      "\\caption*{Test results}\n",
      "\\begin{tabular}{lrr}\n",
      "\\hline\n",
      "              &   Non-Bankrupt &   Bankrupt \\\\\n",
      "\\hline\n",
      " Non-Bankrupt &           1094 &          6 \\\\\n",
      " Bankrupt     &             73 &          9 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{minipage}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = data_handler.load_data(5, out_frame=False)\n",
    "logit_parameters = {\n",
    "    'C': 1.2, \n",
    "    'l1_ratio': 0,\n",
    "    'penalty': 'elasticnet', \n",
    "    'solver': 'saga',\n",
    "    'max_iter': 500\n",
    "}\n",
    "logit_best_model = result_wrapper(LogisticRegression, logit_parameters, (x_train, y_train), (x_test, y_test), \"Logit\")"
   ]
  },
  {
   "source": [
    "This prints the most important logit coefficients"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_important_coeff(model, n_coeffs):\n",
    "    important_coeff_arg = np.flip(\n",
    "        np.argsort(np.abs(logit_best_model['estimator'].coef_))\n",
    "    )\n",
    "    coeff_names = data_handler.ohlson_varnames()\n",
    "\n",
    "    coeff_list = []\n",
    "    name_list = []\n",
    "    for i in range(0, n_coeffs + 1):\n",
    "        coeff_arg = important_coeff_arg[0, i]\n",
    "        coeff_list.append(round(logit_best_model['estimator'].coef_[0, coeff_arg], 3))\n",
    "        name_list.append(coeff_names[i])\n",
    "    return coeff_list, name_list\n",
    "\n",
    "def print_two_rows(coeff_list, name_list):\n",
    "    # Split list in two and rezip them\n",
    "    zipped_list = list(zip(coeff_list, name_list))\n",
    "    zipped1 = zipped_list[:5]\n",
    "    zipped2 = zipped_list[5:]\n",
    "    zipped_list2 = zip(zipped1, zipped2)\n",
    "    table = tabulate(zipped_list2, tablefmt='latex')\n",
    "\n",
    "    # Remove tuple and list specifiers\n",
    "    for char in [\"'\", \"(\", \")\", \"[\", \"]\"]:\n",
    "        table = table.replace(char, '')\n",
    "\n",
    "    # Make some small adjustments to get a pretty list\n",
    "    table = table.replace(\"ll\", \"llll\")\n",
    "    table = table.replace(\",\", \" &\")\n",
    "    table = table.replace(\"cash + short-term securities + receivables - short-term liabilities / operating expenses - depreciation * 365\", \"defensive interval ratio\")\n",
    "    # table = table.replace(\"'\", '').replace(\"(\", '').replace(\")\", '').replace(\"[\",\"\").replace(\"[\",\"\")\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{tabular}{llll}\n\\hline\n net profit / total assets & -0.39                                                                                            & retained earnings / total assets & 0.267          \\\\\n total liabilities / total assets & -0.369                                                                                    & EBIT / total assets & -0.171                      \\\\\n working capital / total assets & -0.366                                                                                      & book value of equity / total liabilities & -0.131 \\\\\n current assets / short-term liabilities & -0.311                                                                             & sales / total assets & -0.128                     \\\\\n defensive interval ratio & -0.298 & equity / total assets & 0.122                     \\\\\n\\hline\n\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "coeff_list, name_list = print_important_coeff(logit_best_model, 10)\n",
    "print_two_rows(name_list, coeff_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decision Tree & 37 & 68.71 & 5.45 & 9.08 \\\\\n\n\\begin{table}[!hb]\n\\centering\n\\caption{Confusion matrix for Decision Tree model} \n\\begin{minipage}{.5\\linewidth}\n\\caption*{Train results}\n\\begin{tabular}{lrr}\n\\hline\n              &   Non-Bankrupt &   Bankrupt \\\\\n\\hline\n Non-Bankrupt &           4337 &         63 \\\\\n Bankrupt     &            156 &        172 \\\\\n\\hline\n\\end{tabular}\n\\end{minipage}\n\\begin{minipage}{.5\\linewidth}\n\\caption*{Test results}\n\\begin{tabular}{lrr}\n\\hline\n              &   Non-Bankrupt &   Bankrupt \\\\\n\\hline\n Non-Bankrupt &           1072 &         28 \\\\\n Bankrupt     &             45 &         37 \\\\\n\\hline\n\\end{tabular}\n\\end{minipage}\n\\end{table}\n"
     ]
    }
   ],
   "source": [
    "dt_parameters = {\n",
    "    'max_leaf_nodes': 11,  #19\n",
    "    'max_depth': 5,  #7\n",
    "    'min_samples_leaf': 0.01,\n",
    "    'min_samples_split': 0.01,\n",
    "    'min_weight_fraction_leaf': 0,\n",
    "    'min_impurity_decrease': 0\n",
    "}\n",
    "dt_best_model = result_wrapper(\n",
    "    DecisionTreeClassifier, dt_parameters, (x_train, y_train), (x_test, y_test), \"Decision Tree\", scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'bankruptcy.pdf'"
      ]
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(\n",
    "    dt_best_model['estimator'], \n",
    "    out_file=None, \n",
    "    feature_names=data_handler.ohlson_varnames(),\n",
    "    class_names=['non-bankrupt', 'bankrupt'],\n",
    "    rounded=True, filled=True\n",
    ") \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"bankruptcy\") "
   ]
  },
  {
   "source": [
    "### Gradient Descent classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Gradient Boosting & 49 & 68.71 & 6.69 & 11.15 \\\\\n\n\\begin{table}[!hb]\n\\centering\n\\caption{Confusion matrix for Gradient Boosting model} \n\\begin{minipage}{.5\\linewidth}\n\\caption*{Train results}\n\\begin{tabular}{lrr}\n\\hline\n              &   Non-Bankrupt &   Bankrupt \\\\\n\\hline\n Non-Bankrupt &           4391 &          9 \\\\\n Bankrupt     &             28 &        300 \\\\\n\\hline\n\\end{tabular}\n\\end{minipage}\n\\begin{minipage}{.5\\linewidth}\n\\caption*{Test results}\n\\begin{tabular}{lrr}\n\\hline\n              &   Non-Bankrupt &   Bankrupt \\\\\n\\hline\n Non-Bankrupt &           1081 &         19 \\\\\n Bankrupt     &             33 &         49 \\\\\n\\hline\n\\end{tabular}\n\\end{minipage}\n\\end{table}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'fit_time': 18.790141820907593,\n",
       " 'score_time': 0.01628708839416504,\n",
       " 'estimator': GradientBoostingClassifier(learning_rate=0.9, max_depth=8,\n",
       "                            min_samples_leaf=0.005, min_samples_split=0.005,\n",
       "                            random_state=42),\n",
       " 'test_score': 0.9325757575757576,\n",
       " 'train_score': 1.0}"
      ]
     },
     "metadata": {},
     "execution_count": 192
    }
   ],
   "source": [
    "GBC_parameters = {\n",
    "    \"learning_rate\": 0.9,\n",
    "    \"min_samples_split\": 0.005,\n",
    "    \"min_samples_leaf\": 0.005,\n",
    "    \"max_depth\": 8,\n",
    "    'random_state': 42\n",
    "}\n",
    "result_wrapper(GradientBoostingClassifier, GBC_parameters, (x_train, y_train), (x_test, y_test), \"Gradient Boosting\", scoring='roc_auc')"
   ]
  },
  {
   "source": [
    "### Neural network\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/karl/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "Neural network & 42 & 68.71 & 6.70 & 11.17 \\\\\n",
      "\n",
      "\\begin{table}[!hb]\n",
      "\\centering\n",
      "\\caption{Confusion matrix for Neural network model} \n",
      "\\begin{minipage}{.5\\linewidth}\n",
      "\\caption*{Train results}\n",
      "\\begin{tabular}{lrr}\n",
      "\\hline\n",
      "              &   Non-Bankrupt &   Bankrupt \\\\\n",
      "\\hline\n",
      " Non-Bankrupt &           4366 &         34 \\\\\n",
      " Bankrupt     &             52 &        276 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{minipage}\n",
      "\\begin{minipage}{.5\\linewidth}\n",
      "\\caption*{Test results}\n",
      "\\begin{tabular}{lrr}\n",
      "\\hline\n",
      "              &   Non-Bankrupt &   Bankrupt \\\\\n",
      "\\hline\n",
      " Non-Bankrupt &           1070 &         30 \\\\\n",
      " Bankrupt     &             40 &         42 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{minipage}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "nn_parameters = {\n",
    "    'solver': 'lbfgs',\n",
    "    'random_state': 42,\n",
    "    'warm_start': False,\n",
    "    'hidden_layer_sizes': 190,\n",
    "    'max_iter': 200\n",
    "}\n",
    "result_wrapper(MLPClassifier, nn_parameters, (x_train, y_train), (x_test, y_test), \"Neural network\") ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}